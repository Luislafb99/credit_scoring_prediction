# 游늷Credit Scoring Prediction游눱游늵

Uno de los mayores desaf칤os en las entidades financieras es lidiar con clientes morosos. La soluci칩n m치s eficaz es abordar este problema antes de otorgar un cr칠dito.

<p align="center">
  <img src="https://github.com/Luislafb99/credit_scoring_prediction/assets/152426197/c7981011-de08-4aa4-8c7b-499df41e90c5" alt="Prediction Image" style="display:block; margin:auto; width:30%;" />
</p>

**쮺칩mo prevenimos este problema?**

La prevenci칩n se lograr치 mediante predicciones sobre nuestros clientes. Utilizando los datos disponibles de los clientes, anticiparemos si ser치n buenos clientes o si presentar치n problemas de morosidad. Este proceso se llevar치 a cabo mediante modelos de machine learning.

Dentro de nuestra base de datos, compararemos el rendimiento de tres modelos de machine learning para determinar cu치l es m치s efectivo en este escenario. Los modelos que evaluaremos son:
- K - Nearest Neighbors
- Naive-Bayes Bernoulli
- 츼rboles de Decisi칩n

Este an치lisis nos permitir치 seleccionar el modelo m치s adecuado para predecir y gestionar el riesgo crediticio de manera eficiente.


## 游늷Configuraci칩n del entorno

En este proyecto, emplearemos el lenguaje de programaci칩n Python junto con sus bibliotecas fundamentales, como pandas, seaborn, matplotlib y sklearn.

Definiremos dos variables globales clave:

-**df_banco**: Almacener치 una copia de la base de datos que contiene el historial crediticio de los clientes, una medida preventiva para gestionar eficientemente los datos.

-**resultados**: Un diccionario que se utilizar치 para almacenar las m칠tricas de rendimiento de los modelos, facilitando la comparaci칩n entre ellos.


## 游늷Preprocesamiento de datos

En este apartado, nos enfocaremos en la detecci칩n y eliminaci칩n de posibles entradas duplicadas, as칤 como en el manejo de datos nulos utilizando la biblioteca pandas. Adem치s, ejecutaremos la conversi칩n de valores categ칩ricos a num칠ricos. Todas estas operaciones ser치n llevadas a cabo de manera eficiente dentro de la funci칩n **procesar_datos()**.


## 游늷Exploraci칩n de datos 游늵

En el proceso de An치lisis Exploratorio de Datos (EDA), nos propusimos evaluar si variables como sexo, edad, tiempo de pago del cr칠dito y monto son significativas. Para realizar esto, filtramos los datos y creamos nuevos atributos dentro de la funci칩n feature_engineering().

A continuaci칩n, presentamos algunos datos relevantes visualizados:
<p align="center">
<img width="755" alt="image" src="https://github.com/Luislafb99/credit_scoring_prediction/assets/152426197/8122e58f-1070-4461-bf8f-28095f0cec03">
</p>
La variable objetivo es Default, donde 0 indica que un titular no es moroso y 1 indica que s칤 lo es. Observamos un desbalance en los datos, ya que contamos con 700 buenos clientes y 300 malos clientes. Para abordar este desequilibrio, optamos por utilizar SMOTE, una t칠cnica dise침ada para contrarrestar el desbalance de clases en conjuntos de datos. Esto ayudar치 a reducir el sesgo asociado a la clase subrepresentada, mejorando as칤 los resultados de nuestros modelos. Para implementar SMOTE, utilizaremos la librer칤a imblearn.over_sampling.

Adem치s, examinamos la correlaci칩n entre las variables, especialmente con respecto a Default:

<p align="center">
<img width="741" alt="image" src="https://github.com/Luislafb99/credit_scoring_prediction/assets/152426197/026ca2f8-9382-452d-8c30-930abad54b74">
</p>

Observamos que algunos atributos pueden ser eliminados despu칠s de la creaci칩n de los nuevos atributos mencionados anteriormente, por lo tanto, procedimos a eliminarlos.

Este an치lisis nos permitir치 tomar decisiones informadas sobre qu칠 variables son m치s relevantes para nuestros modelos y realizar las modificaciones necesarias para mejorar la calidad de los datos.

## 游늷Construcci칩n de modelos

En la construcci칩n de modelos, dividimos entre datos de entrenamiento(train) y datos de prueba(test) y normalizamos los datos, esto para poder tener mejores resultados con la implementaci칩n de los modelos.
Las librerias y m칠todos que se usaron fueron:
<p align="center">
<img width="466" alt="image" src="https://github.com/Luislafb99/credit_scoring_prediction/assets/152426197/fecd73c9-a727-4ae1-90cc-cbc2eb1fa925">
</p>
De estos m칠todos usamos .fit() y .prediction(), para entrenar y realizar predicciones con los datos que tomamos como x_test.

Los resultados se muetran en las siguientes matrices de confusi칩n:
<p align="center">
<img width="762" alt="image" src="https://github.com/Luislafb99/credit_scoring_prediction/assets/152426197/f18cc726-b96a-4222-8fb1-b2cf5b46c07d">
</p>

## 游늷Evaluaci칩n y selecci칩n de modelos

Para la selecci칩n de modelos tomamos las metricas de Accuracy, Recall, Precisi칩n, F1_Score y Auc_Roc.
<p align="center">
<img width="740" alt="image" src="https://github.com/Luislafb99/credit_scoring_prediction/assets/152426197/0c179942-993d-4558-8428-7b08b0770370">
</p>



























Este proyecto utiliza el conjunto de datos "German Credit data". La informaci칩n sobre la fuente original de los datos es la siguiente:

- **T칤tulo:** German Credit data
- **Fuente:** Professor Dr. Hans Hofmann, Institut f"ur Statistik und "Okonometrie, Universit"at Hamburg, FB Wirtschaftswissenschaften, Von-Melle-Park 5, 2000 Hamburg 13








