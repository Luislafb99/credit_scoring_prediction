# Credit Scoring Prediction仇

Uno de los mayores desaf铆os en las entidades financieras es lidiar con clientes morosos. La soluci贸n m谩s eficaz es abordar este problema antes de otorgar un cr茅dito.

<p align="center">
  <img src="https://github.com/Luislafb99/credit_scoring_prediction/assets/152426197/c7981011-de08-4aa4-8c7b-499df41e90c5" alt="Prediction Image" style="display:block; margin:auto; width:30%;" />
</p>

**驴C贸mo prevenimos este problema?**

La prevenci贸n se lograr谩 mediante predicciones sobre nuestros clientes. Utilizando los datos disponibles de los clientes, anticiparemos si ser谩n buenos clientes o si presentar谩n problemas de morosidad. Este proceso se llevar谩 a cabo mediante modelos de machine learning.

Dentro de nuestra base de datos, compararemos el rendimiento de tres modelos de machine learning para determinar cu谩l es m谩s efectivo en este escenario. Los modelos que evaluaremos son:
- K - Nearest Neighbors
- Naive-Bayes Bernoulli
- rboles de Decisi贸n

Este an谩lisis nos permitir谩 seleccionar el modelo m谩s adecuado para predecir y gestionar el riesgo crediticio de manera eficiente.


## Configuraci贸n del entorno

En este proyecto, emplearemos el lenguaje de programaci贸n Python junto con sus bibliotecas fundamentales, como pandas, seaborn, matplotlib y sklearn.

Definiremos dos variables globales clave:

-**df_banco**: Almacener谩 una copia de la base de datos que contiene el historial crediticio de los clientes, una medida preventiva para gestionar eficientemente los datos.

-**resultados**: Un diccionario que se utilizar谩 para almacenar las m茅tricas de rendimiento de los modelos, facilitando la comparaci贸n entre ellos.


## Preprocesamiento de datos

En este apartado, nos enfocaremos en la detecci贸n y eliminaci贸n de posibles entradas duplicadas, as铆 como en el manejo de datos nulos utilizando la biblioteca pandas. Adem谩s, ejecutaremos la conversi贸n de valores categ贸ricos a num茅ricos. Todas estas operaciones ser谩n llevadas a cabo de manera eficiente dentro de la funci贸n **procesar_datos()**.


## Exploraci贸n de datos 

En el proceso de An谩lisis Exploratorio de Datos (EDA), nos propusimos evaluar si variables como sexo, edad, tiempo de pago del cr茅dito y monto son significativas. Para realizar esto, filtramos los datos y creamos nuevos atributos dentro de la funci贸n feature_engineering().

A continuaci贸n, presentamos algunos datos relevantes visualizados:
<p align="center">
<img width="755" alt="image" src="https://github.com/Luislafb99/credit_scoring_prediction/assets/152426197/8122e58f-1070-4461-bf8f-28095f0cec03">
</p>
La variable objetivo es Default, donde 0 indica que un titular no es moroso y 1 indica que s铆 lo es. Observamos un desbalance en los datos, ya que contamos con 700 buenos clientes y 300 malos clientes. Para abordar este desequilibrio, optamos por utilizar SMOTE, una t茅cnica dise帽ada para contrarrestar el desbalance de clases en conjuntos de datos. Esto ayudar谩 a reducir el sesgo asociado a la clase subrepresentada, mejorando as铆 los resultados de nuestros modelos. Para implementar SMOTE, utilizaremos la librer铆a imblearn.over_sampling.

Adem谩s, examinamos la correlaci贸n entre las variables, especialmente con respecto a Default:

<p align="center">
<img width="741" alt="image" src="https://github.com/Luislafb99/credit_scoring_prediction/assets/152426197/026ca2f8-9382-452d-8c30-930abad54b74">
</p>

Observamos que algunos atributos pueden ser eliminados despu茅s de la creaci贸n de los nuevos atributos mencionados anteriormente, por lo tanto, procedimos a eliminarlos.

Este an谩lisis nos permitir谩 tomar decisiones informadas sobre qu茅 variables son m谩s relevantes para nuestros modelos y realizar las modificaciones necesarias para mejorar la calidad de los datos.

## Construcci贸n de modelos

En la construcci贸n de modelos, dividimos entre datos de entrenamiento(train) y datos de prueba(test) y normalizamos los datos, esto para poder tener mejores resultados con la implementaci贸n de los modelos.
Las librerias y m茅todos que se usaron fueron:
<p align="center">
<img width="466" alt="image" src="https://github.com/Luislafb99/credit_scoring_prediction/assets/152426197/fecd73c9-a727-4ae1-90cc-cbc2eb1fa925">
</p>
De estos m茅todos usamos .fit() y .prediction(), para entrenar y realizar predicciones con los datos que tomamos como x_test.

Los resultados se muetran en las siguientes matrices de confusi贸n:
<p align="center">
<img width="762" alt="image" src="https://github.com/Luislafb99/credit_scoring_prediction/assets/152426197/f18cc726-b96a-4222-8fb1-b2cf5b46c07d">
</p>

## Evaluaci贸n y selecci贸n de modelos

Para la selecci贸n de modelos tomamos las metricas de Accuracy, Recall, Precisi贸n, F1_Score y Auc_Roc.
<p align="center">
<img width="740" alt="image" src="https://github.com/Luislafb99/credit_scoring_prediction/assets/152426197/0c179942-993d-4558-8428-7b08b0770370">
</p>

El modelo KNN destaca en t茅rminos de precisi贸n general (accuracy), precisi贸n en la identificaci贸n de clientes morosos (precision), y equilibrio entre precisi贸n y capacidad para identificar morosos (F1_Score). Aunque el modelo de 谩rbol de decisi贸n tiene un recall ligeramente superior (capacidad para identificar morosos), el KNN logra un buen equilibrio entre todas las m茅tricas. Por lo tanto, bas谩ndonos en el conjunto de m茅tricas y considerando los objetivos del negocio, el modelo KNN parece ser la elecci贸n preferida.




Este proyecto utiliza el conjunto de datos "German Credit data". La informaci贸n sobre la fuente original de los datos es la siguiente:

- **T铆tulo:** German Credit data
- **Fuente:** Professor Dr. Hans Hofmann, Institut f"ur Statistik und "Okonometrie, Universit"at Hamburg, FB Wirtschaftswissenschaften, Von-Melle-Park 5, 2000 Hamburg 13








